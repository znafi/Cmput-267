{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/znafi/Cmput-267/blob/main/ass5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yt74G5cLSiAU",
        "outputId": "e4388f92-0f8e-4e29-f4c6-641e84fb392c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.8/118.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Enable widgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Install otter-grader\n",
        "%pip install -q otter-grader==6.1.6\n",
        "\n",
        "# Download the tests directory from the course website (this will be used by otter-grader)\n",
        "!wget -q https://vladtkachuk4.github.io/machinelearning1/assignments/Fall2025/ass5/tests.zip -O tests.zip\n",
        "\n",
        "# Unzip the tests directory, forcing overwriting of existing files\n",
        "!unzip -qo tests.zip -d ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp5n8ENUSiAV"
      },
      "outputs": [],
      "source": [
        "# Initialize Otter\n",
        "import otter\n",
        "grader = otter.Notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4rnBsaVSiAV"
      },
      "source": [
        "# CMPUT 267 - Machine Learning I\n",
        "# Assignment 5 - Evaluating Predictors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxRiNtC1SiAW"
      },
      "source": [
        "## Assignment Instructions and Information\n",
        "For this assignment, we will be using Google Colab. If you are new to Google Colab, you can find a brief introduction at the following link: [Google Colab Introduction](https://colab.research.google.com/notebooks/intro.ipynb).\n",
        "\n",
        "**Important:** Before you start working on this notebook, make sure to save a copy to your own Google Drive. To do this, go to `File` -> `Save a copy in Drive`.\n",
        "\n",
        "If you do not save a copy, you will not be able to save any changes you make.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujyCTCelSiAW"
      },
      "source": [
        "### Submitting your assignment\n",
        "Once you have completed the assignment, please submit your work as a `.ipynb` file on eClass in the \"Assignment 5\" section. To download your Colab notebook in the required format, follow these steps:\n",
        "\n",
        "1. Save your notebook to ensure all changes are preserved.\n",
        "2. Navigate to `File` -> `Download` -> `Download .ipynb`.\n",
        "\n",
        "Make sure to save your notebook before downloading it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDZu67oYSiAW"
      },
      "source": [
        "### Questions and Autograding\n",
        "\n",
        "Each section contains questions for you to solve, marked with the subsection heading \"Question X.Y\" (ex: the first problem is \"Question 1.1\").\n",
        "\n",
        "For each question your solution must go within the following designated code block:\n",
        "\n",
        "```python\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "######################\n",
        "```\n",
        "\n",
        "All questions will be autograded using [Otter-Grader](https://otter-grader.readthedocs.io/en/latest/).\n",
        "The first two code cells in this notebook install the Otter-Grader package and download the test cases.\n",
        "You should run these cells, otherwise the autograder will not work.\n",
        "\n",
        "At the end of each question there is code that runs the autograder. For example, in Question 1.1 the code `grader.check(\"q1_1\")` runs the autograder.\n",
        "If you pass all the test cases for a question (ex: Question 1.1), you will see the following output:\n",
        "\n",
        "**q1_1** passed!\n",
        "\n",
        "If you do not pass all the test cases for a question, you will see which test cases you did not pass along with their corresponding error messages.\n",
        "\n",
        "There are both public and private test cases. You only have access to the public test cases. This means that if you pass all the test cases in this notebook, you have passed all the public test cases.\n",
        "\n",
        "After you submit the assignment, we will also run the private test cases. The public test cases account for 50% of the total mark, while the private test cases make up the remaining 50%. Therefore, if you pass all the test cases in the notebook, you are guaranteed a mark of at least 50%.\n",
        "\n",
        "After each question description, the number of points (marks) the question is worth is indicated.\n",
        "This is the total number of points for both the public and private test cases.\n",
        "For each question, the public test cases are worth 50% of the points.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckHsEBSYSiAW"
      },
      "source": [
        "### Math Rendering Issues\n",
        "If you're encountering issues with math rendering in your notebook, particularly small squares replacing math symbols, this is a common problem, especially for users of Google Chrome. Fortunately, there's an easy fix.\n",
        "\n",
        "Hold down `Ctrl` on your keyboard and click on the small square. Then select: Math Settings -> Math Renderer -> Common HTML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWPrmLcCSiAW"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Welcome to Assignment 5! In this assignment, you will explore evaluating predictors.\n",
        "We will be focusing on the methods discussed in Chapter 7 of the [course notes](https://vladtkachuk4.github.io/machinelearning1/notes.pdf).\n",
        "\n",
        "This assignment will guide you through the following sections:\n",
        "\n",
        "1. [Visualizing Different Errors](#part-1-visualizing-different-errors)\n",
        "1. [Picking the Best Polynomial Predictor](#part-2-picking-the-best-polynomial-predictor)\n",
        "1. [Regularization](#part-3-regularization)\n",
        "\n",
        "You can quickly navigate to each section by opening the table of contents on the left side of the screen.\n",
        "\n",
        "Let's get started!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWf34fuRSiAW"
      },
      "source": [
        "# Part 1: Visualizing Different Errors\n",
        "\n",
        "In this assignment we will use synthetic data that we generate ourselves.\n",
        "This means that we have access to the feature-label distribution $\\mathbb{P}_{\\boldsymbol{X}, Y}$.\n",
        "This is useful because it allows us to calculate the expected loss $L$ of our predictors.\n",
        "\n",
        "To make visualizing things easier, we will use a 1-dimensional features (i.e. $d=1$).\n",
        "Thus,\n",
        "$$\\mathcal{X} = \\mathbb{R}^{d+1} = \\mathbb{R}^2 \\quad \\text{and} \\quad \\mathcal{Y} = \\mathbb{R}$$\n",
        "\n",
        "Since we are working in the regression setting we will be using the squared loss function\n",
        "$$\\ell(\\hat{y}, y) = (\\hat{y} - y)^2.$$\n",
        "\n",
        "In this section our goal will be to visualize and build a better understanding of the different error terms we encounter when trying to minimize $\\mathbb{E}[L(\\mathcal{A}(D))]$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlIYAKHdSiAW"
      },
      "source": [
        "To get started, lets import all the necessary libraries for this assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncQPcg2aSiAW"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from ipywidgets import interactive_output\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Set a fixed random seed for reproducibility\n",
        "random_seed = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vVtkHvHSiAW"
      },
      "source": [
        "Now, lets visualize the best possible predictor\n",
        "$$f_\\text{Bayes} = \\arg\\min_{f \\in \\{f | f: \\mathcal{X} \\to \\mathcal{Y}\\}} L(f).$$\n",
        "and what $\\mathbb{P}_{\\boldsymbol{X}, Y}$ looks like by ploting 1000 samples from it.\n",
        "\n",
        "One way to interpret $f_\\text{Bayes}$ is as the predictor that best fits infinitely many samples from $\\mathbb{P}_{\\boldsymbol{X}, Y}$.\n",
        "Since we can not plot infinitely many samples we only plotted finitely many (1000 in this case)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9TTspU-hSiAW"
      },
      "outputs": [],
      "source": [
        "# @title Plot\n",
        "\n",
        "# Define the coefficients for f_Bayes\n",
        "coefficients = [1, 7, -6, 1.2, 0.1, -0.02, 0.001, 0, -0.0002]\n",
        "\n",
        "# Define a polynomial function\n",
        "def polynomial(coeffs):\n",
        "    def poly_func(x):\n",
        "        return sum(c * x**i for i, c in enumerate(coeffs))\n",
        "    return poly_func\n",
        "\n",
        "# Define f_Bayes\n",
        "f_bayes = polynomial(coefficients)\n",
        "\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Number of data points\n",
        "num_points_plot = 1000\n",
        "\n",
        "# Generate X values uniformly between 0 and 4\n",
        "X_plot = np.random.uniform(0, 4, num_points_plot)\n",
        "\n",
        "# Generate noise from a Gaussian distribution with mean 0 and variance 1\n",
        "noise_plot = np.random.normal(0, 1, num_points_plot)\n",
        "\n",
        "# Calculate Y values using f_Bayes and adding noise\n",
        "Y_plot = f_bayes(X_plot) + noise_plot\n",
        "\n",
        "# Generate x values for plotting\n",
        "x = np.linspace(0, 4, 400)\n",
        "\n",
        "# Define the function to update the plot based on the checkbox value\n",
        "def update_plot_f_bayes(show_plot):\n",
        "    if show_plot:\n",
        "        # Plot the generated data points\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.scatter(X_plot, Y_plot, alpha=0.5, label=r'Samples from $\\mathbb{P}_{X, Y}$')\n",
        "        plt.plot(x, f_bayes(x), color='black', label=r'$f_{Bayes}$', linewidth=3)\n",
        "        plt.xlabel('X')\n",
        "        plt.ylabel('Y')\n",
        "        plt.ylim(0.2, 7.2)\n",
        "        plt.xlim(-0.2, 4.2)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        clear_output()\n",
        "        # plt.close()\n",
        "\n",
        "# Create a checkbox for showing/hiding the plot\n",
        "show_plot_checkbox_f_bayes = widgets.Checkbox(value=False, description='Show Plot')\n",
        "\n",
        "# Use interactive_output to update the plot based on the checkbox value\n",
        "interactive_plot_f_bayes = widgets.interactive_output(update_plot_f_bayes, {'show_plot': show_plot_checkbox_f_bayes})\n",
        "\n",
        "# Display the checkbox and the plot\n",
        "display(show_plot_checkbox_f_bayes, interactive_plot_f_bayes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk3ZHS71SiAW"
      },
      "source": [
        "Now we would like to see what the best predictor in a polynomial degree $p$ function class $\\cal{F}_p$ looks like.\n",
        "In particular, the predictor\n",
        "$$f^*_p = \\arg\\min_{f \\in \\cal{F}_p} L(f)$$\n",
        "where\n",
        "$$\\cal{F}_p = \\{f | f: \\mathcal{X} \\to \\mathcal{Y}, \\text{ where } f(\\boldsymbol{x}) = \\phi_p(\\boldsymbol{x})^\\top \\boldsymbol{w}, \\text{ and } \\boldsymbol{w} \\in \\mathbb{R}^{\\bar p}\\}$$\n",
        "To do this we will need an implemention of the polynomial feature map $\\phi_p$ for various values of $p$.\n",
        "To test your understanding we will only ask you to implement $\\phi_3$.\n",
        "\n",
        "After your implementation, we provide you with a more general implementation of $\\phi_p$ for any $p$, that will be used for the rest of the assignment.\n",
        "\n",
        "**Do not just copy the code from `phi_p` into the cell where you are asked to implement $\\phi_3$. You will get zero marks for that.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp2x3IA1SiAX"
      },
      "source": [
        "### Question 1.1\n",
        "\n",
        "Implement `phi_3`.\n",
        "\n",
        "_Points:_ 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60knU7OISiAX"
      },
      "outputs": [],
      "source": [
        "def phi_3(x):\n",
        "    \"\"\"\n",
        "    Transforms a single feature vector into a polynomial of degree 3 feature vector.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy array): A single feature vector of size d+1.\n",
        "\n",
        "    Returns:\n",
        "    poly_features (numpy array): A transformed feature vector of size (d+1)*(d+2)*(d+3)/6.\n",
        "    \"\"\"\n",
        "    # Calculate the size of the transformed feature vector\n",
        "    d = len(x) - 1\n",
        "    size = (d+1) * (d+2) * (d+3) // 6\n",
        "\n",
        "    ### YOUR CODE HERE ###\n",
        "\n",
        "    poly_features = np.random.rand(size) # this is a placeholder, replace it with the correct value\n",
        "\n",
        "    ######################\n",
        "\n",
        "    return poly_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4jmNNbNSiAX"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q1_1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xYKXgVQSiAX"
      },
      "source": [
        "Below is the `phi_p` function that implements $\\phi_p$ for any $p$, which we will use for the rest of the assignment.\n",
        "We directly add normalization the the end of the `phi_p` function, so that we don't have to constantly normalize the features after applying the `phi_p` function each time.\n",
        "The purpose of normalization was discussed in assignment 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ixjx_OIuSiAX"
      },
      "outputs": [],
      "source": [
        "def phi_p(X, p):\n",
        "    \"\"\"\n",
        "    Transforms the input feature matrix X into polynomial features of degree p and normalizes them.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Input feature matrix where each row is a feature vector.\n",
        "    p (int): Degree of the polynomial features.\n",
        "\n",
        "    Returns:\n",
        "    poly_features (numpy.ndarray): Transformed and normalized polynomial features.\n",
        "    \"\"\"\n",
        "    # Create PolynomialFeatures instance with the desired degree\n",
        "    poly = PolynomialFeatures(degree=p, include_bias=True)\n",
        "\n",
        "    # Transform the feature matrix to polynomial features\n",
        "    poly_features = poly.fit_transform(X[:, 1:])\n",
        "\n",
        "    # Normalize the polynomial features, excluding the first column\n",
        "    poly_features[:, 1:] = (poly_features[:, 1:] - np.mean(poly_features[:, 1:], axis=0)) / np.std(poly_features[:, 1:], axis=0)\n",
        "\n",
        "    return poly_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg0DlvFNSiAX"
      },
      "source": [
        "Lets plot $f^*_p$ for various values of $p$ and compare it to $f_\\text{Bayes}$.\n",
        "\n",
        "You can use the slider to select different values of $p$.\n",
        "\n",
        "Notice how as $p$ increases, $f^*_p$ is able to better approximate $f_\\text{Bayes}$.\n",
        "This is because $\\cal{F}_p$ is a richer function class as $p$ increases, and for large enough $p$, we will even have that $f_\\text{Bayes} \\in \\cal{F}_p$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "12pjydKaSiAX"
      },
      "outputs": [],
      "source": [
        "# @title Plot\n",
        "\n",
        "np.random.seed(random_seed)\n",
        "# num_points = 1000000\n",
        "num_points = 10000\n",
        "X_exp = np.random.uniform(0, 4, num_points)\n",
        "noise_exp = np.random.normal(0, 1, num_points)\n",
        "Y_exp = f_bayes(X_exp) + noise_exp\n",
        "\n",
        "# Define the function to update the plot based on the selected degree and checkbox value\n",
        "def update_plot_f_star(degree, show_plot):\n",
        "    if show_plot:\n",
        "        # Fit the polynomial to the data\n",
        "        w_star = np.polyfit(X_exp, Y_exp, degree)\n",
        "\n",
        "        # Generate y values for the fitted polynomial\n",
        "        f_star = np.polyval(w_star, x)\n",
        "\n",
        "        # Plot the generated data points and the polynomial fit\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(x, f_bayes(x), color='black', label=r'$f_{Bayes}$', linewidth=3)\n",
        "        plt.plot(x, f_star, color='green', linestyle='-', label=fr'$f^*_{degree}$', linewidth=3)\n",
        "        plt.xlabel('X')\n",
        "        plt.ylabel('Y')\n",
        "        plt.ylim(0.2, 7.2)\n",
        "        plt.xlim(-0.2, 4.2)\n",
        "        plt.legend(loc='upper left')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        clear_output()\n",
        "\n",
        "# Create sliders for the polynomial degree and a checkbox for showing/hiding the plot\n",
        "degree_slider_f_star = widgets.IntSlider(value=1, min=1, max=9, step=1, description='Degree p')\n",
        "show_plot_checkbox_f_star = widgets.Checkbox(value=False, description='Show Plot')\n",
        "\n",
        "# Use interactive_output to update the plot based on the slider and checkbox values\n",
        "interactive_plot_f_star = widgets.interactive_output(update_plot_f_star, {'degree': degree_slider_f_star, 'show_plot': show_plot_checkbox_f_star})\n",
        "\n",
        "# Display the sliders, checkbox, and the plot\n",
        "display(degree_slider_f_star, show_plot_checkbox_f_star, interactive_plot_f_star)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voW4yuvESiAX"
      },
      "source": [
        "Now, we would like to plot the best predictor based on a dataset of size $n$.\n",
        "In particular, the predictor\n",
        "$$\\hat f_{p} = \\arg\\min_{f \\in \\cal{F}_p} \\hat L(f).$$\n",
        "Recall that the closed form linear regression learner outputs exactly this predictor.\n",
        "Since you have already implemented it in the previous assignment, we will provide you with the implementation of the learner below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVS0BpU0SiAX"
      },
      "outputs": [],
      "source": [
        "def closed_form_learner(X, Y):\n",
        "    '''\n",
        "    Solves linear regression using the closed form solution.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy array): Feature matrix of size (n, d+1), where n is the number of samples\n",
        "                     and d is the number of features. The first column should be all 1s.\n",
        "    Y (numpy array): Target vector of size (n, 1).\n",
        "\n",
        "    Returns:\n",
        "    predictor (function): A function that takes a feature vector and returns a predicted value.\n",
        "    w_hat (numpy array): The weights calculated using the closed form solution.\n",
        "    '''\n",
        "\n",
        "    A = X.T @ X\n",
        "    b = X.T @ Y\n",
        "    w_hat = np.linalg.pinv(A) @ b\n",
        "\n",
        "    def predictor(x):\n",
        "        return x @ w_hat\n",
        "\n",
        "    return predictor, w_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry08dzgjSiAX"
      },
      "source": [
        "We can add $\\hat f_{p}$ to our previous plot and see how it compares.\n",
        "\n",
        "We have added 2 more sliders so that you can change the size of the dataset $n$ and the random seed used to generate the dataset.\n",
        "Changing the random seed should be thought of as getting an entirely new dataset of size $n$.\n",
        "\n",
        "The orange dots are the data points from the dataset.\n",
        "You should notice that as $n$ increases, $\\hat f_{p}$ is a better approximation of $f^*_p$.\n",
        "You should also notice that if you change the random seed, the dataset changes and thus $\\hat f_{p}$ changes.\n",
        "Another thing to notice is that if you increase the degree of the polynomial $p$, more samples $n$ are needed for $\\hat f_p$ to approximate $f^*_p$ well, and if you change the random seed, $\\hat f_{p}$ changes more drastically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kNuEeCIgSiAX"
      },
      "outputs": [],
      "source": [
        "# @title Plot\n",
        "\n",
        "# Define the function to update the plot based on the selected degree, n, and random seed\n",
        "def update_plot_f_hat(degree, n, random_seed, show_plot):\n",
        "    if show_plot:\n",
        "        # Fit the polynomial to the data\n",
        "        w_star = np.polyfit(X_exp, Y_exp, degree)\n",
        "\n",
        "        # Generate y values for the fitted polynomial\n",
        "        f_star = np.polyval(w_star, x)\n",
        "\n",
        "        # Generate new train dataset\n",
        "        np.random.seed(random_seed)\n",
        "        X_train_raw = np.random.uniform(0, 4, n)\n",
        "        X_train = np.c_[np.ones(n), X_train_raw]\n",
        "        noise_train = np.random.normal(0, 1, n)\n",
        "        Y_train = f_bayes(X_train_raw) + noise_train\n",
        "\n",
        "        # Transform the feature matrix to polynomial features\n",
        "        X_train_poly = phi_p(X_train, degree)\n",
        "\n",
        "        # Fit the model using closed form solution\n",
        "        f_hat, w_hat = closed_form_learner(X_train_poly, Y_train)\n",
        "\n",
        "        # Generate y values for the fitted polynomial from closed_form_learner\n",
        "        f_hat_values = f_hat(phi_p(np.c_[np.ones(x.shape[0]), x], degree))\n",
        "\n",
        "        # Plot the generated data points and the polynomial fit\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(x, f_bayes(x), color='black', label=r'$f_{Bayes}$', linewidth=3)\n",
        "        plt.plot(x, f_star, color='green', linestyle='-', label=fr'$f^*_{degree}$', linewidth=3)\n",
        "        plt.plot(x, f_hat_values, color='orange', linestyle='--', label=fr'$\\hat f_{degree}$ with n={n}', linewidth=3)\n",
        "        plt.scatter(X_train_raw, Y_train, color='orange', alpha=0.5, label='Dataset')\n",
        "        plt.xlabel('X')\n",
        "        plt.ylabel('Y')\n",
        "        plt.ylim(0.2, 7.2)\n",
        "        plt.xlim(-0.2, 4.2)\n",
        "        plt.legend(loc='upper left')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        clear_output()\n",
        "\n",
        "# Create sliders for the polynomial degree, n, and random seed\n",
        "degree_slider_f_hat = widgets.IntSlider(value=1, min=1, max=9, step=1, description='Degree p')\n",
        "n_slider_f_hat = widgets.IntSlider(value=10, min=1, max=200, step=1, description='n')\n",
        "random_seed_slider_f_hat = widgets.IntSlider(value=1, min=1, max=10, step=1, description='Random Seed', style={'description_width': 'initial'})\n",
        "show_plot_checkbox_f_hat = widgets.Checkbox(value=False, description='Show Plot')\n",
        "\n",
        "# Use interactive_output to update the plot based on the slider values\n",
        "interactive_plot_f_hat = widgets.interactive_output(update_plot_f_hat,\n",
        "                                                    {'degree': degree_slider_f_hat,\n",
        "                                                     'n': n_slider_f_hat,\n",
        "                                                     'random_seed': random_seed_slider_f_hat,\n",
        "                                                     'show_plot': show_plot_checkbox_f_hat})\n",
        "\n",
        "# Display the sliders and the plot\n",
        "display(degree_slider_f_hat, n_slider_f_hat, random_seed_slider_f_hat, show_plot_checkbox_f_hat, interactive_plot_f_hat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u6NRiOjSiAX"
      },
      "source": [
        "In class we also discussed the expected predictor\n",
        "$$\\bar f_p(x) = \\mathbb{E}[\\hat f_{D, p}(X)|X = x],$$\n",
        "which is the predictor we get after taking the expected value of $\\hat f_{D, p}(x)$ for each $x \\in [0,4]$ over all possible datasets.\n",
        "We have added $D$ to the subscript of $\\hat f_p$ here to emphasize that it is a function of the random variable $D$, thus it it also a random variable and that is what the expectation is taken over.\n",
        "\n",
        "Since it is difficult to calculate this expected value we plot an estimate of $\\bar f_p$ based on 1000 datasets.\n",
        "What you should see is that $\\bar f_p$ is approximately equal to $f^*_p$.\n",
        "Indeed, if we could calculate $\\bar f_p$ exactly then you would see that is equal to $f^*_p$.\n",
        "This is a property that holds when we use the closed form linear regression learner.\n",
        "We will see in [Part 3](#part-3-regularization) that this property does not hold when we use regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rKz2-rcZSiAX"
      },
      "outputs": [],
      "source": [
        "# @title Plot\n",
        "\n",
        "# Define the function to update the plot based on the selected degree, n, and random seed\n",
        "def update_plot_f_bar(degree, n, random_seed, show_plot):\n",
        "    if show_plot:\n",
        "        # Fit the polynomial to the data\n",
        "        w_star = np.polyfit(X_exp, Y_exp, degree)\n",
        "\n",
        "        # Generate y values for the fitted polynomial\n",
        "        f_star = np.polyval(w_star, x)\n",
        "\n",
        "        # Generate new train dataset\n",
        "        np.random.seed(random_seed)\n",
        "        X_train_raw = np.random.uniform(0, 4, n)\n",
        "        X_train = np.c_[np.ones(n), X_train_raw]\n",
        "        noise_train = np.random.normal(0, 1, n)\n",
        "        Y_train = f_bayes(X_train_raw) + noise_train\n",
        "\n",
        "        # Transform the feature matrix to polynomial features\n",
        "        X_train_poly = phi_p(X_train, degree)\n",
        "\n",
        "        # Fit the model using closed form solution\n",
        "        f_hat, w_hat = closed_form_learner(X_train_poly, Y_train)\n",
        "\n",
        "        # Generate y values for the fitted polynomial from closed_form_learner\n",
        "        f_hat_values = f_hat(phi_p(np.c_[np.ones(x.shape[0]), x], degree))\n",
        "\n",
        "        # Calculate the average predictor\n",
        "        num_datasets = 1000\n",
        "        f_bar_values = np.zeros_like(x)\n",
        "\n",
        "        for _ in range(num_datasets):\n",
        "            X_train_raw = np.random.uniform(0, 4, n)\n",
        "            X_train = np.c_[np.ones(n), X_train_raw]\n",
        "            noise_train = np.random.normal(0, 1, n)\n",
        "            Y_train = f_bayes(X_train_raw) + noise_train\n",
        "\n",
        "            X_train_poly = phi_p(X_train, degree)\n",
        "            f_bar, w_bar = closed_form_learner(X_train_poly, Y_train)\n",
        "            f_bar_values += f_bar(phi_p(np.c_[np.ones(x.shape[0]), x], degree))\n",
        "\n",
        "        f_bar_values /= num_datasets\n",
        "\n",
        "        # Plot the generated data points and the polynomial fit\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(x, f_bayes(x), color='black', label=r'$f_{Bayes}$', linewidth=3)\n",
        "        plt.plot(x, f_star, color='green', linestyle='-', label=fr'$f^*_{degree}$', linewidth=3)\n",
        "        plt.plot(x, f_hat_values, color='orange', linestyle='--', label=fr'$\\hat f_{degree}$ with n={n}', linewidth=3)\n",
        "        plt.plot(x, f_bar_values, color='blue', linestyle='-.', label=fr'$\\bar f_{degree}$ over {num_datasets} datasets', linewidth=3)\n",
        "        plt.scatter(X_train_raw, Y_train, color='orange', alpha=0.5, label='Dataset')\n",
        "        plt.xlabel('X')\n",
        "        plt.ylabel('Y')\n",
        "        plt.ylim(0.2, 7.2)\n",
        "        plt.xlim(-0.2, 4.2)\n",
        "        plt.legend(loc='upper left')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        clear_output()\n",
        "\n",
        "# Create sliders for the polynomial degree, n, and random seed\n",
        "degree_slider_f_bar = widgets.IntSlider(value=1, min=1, max=9, step=1, description='Degree p')\n",
        "n_slider_f_bar = widgets.IntSlider(value=10, min=1, max=200, step=1, description='n')\n",
        "random_seed_slider_f_bar = widgets.IntSlider(value=1, min=1, max=10, step=1, description='Random Seed', style={'description_width': 'initial'})\n",
        "show_plot_checkbox_f_bar = widgets.Checkbox(value=False, description='Show Plot')\n",
        "\n",
        "# Use interactive_output to update the plot based on the slider values\n",
        "interactive_plot_f_bar = widgets.interactive_output(update_plot_f_bar,\n",
        "                                                    {'degree': degree_slider_f_bar,\n",
        "                                                     'n': n_slider_f_bar,\n",
        "                                                     'random_seed': random_seed_slider_f_bar,\n",
        "                                                     'show_plot': show_plot_checkbox_f_bar})\n",
        "\n",
        "# Display the sliders and the plot\n",
        "display(degree_slider_f_bar, n_slider_f_bar, random_seed_slider_f_bar, show_plot_checkbox_f_bar, interactive_plot_f_bar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyeURW2ZSiAX"
      },
      "source": [
        "Now we would like to plot the expected and estimated losses of the predictors we have discussed above.\n",
        "To do this you will need to first implement `estimated_loss`, which is the estimate of expected loss, defined as\n",
        "$$\\hat L(f) = \\frac{1}{n} \\sum_{i=1}^n \\ell(f(x_i), y_i).$$\n",
        "Remember that we are using the squared loss.\n",
        "Also, `X` is a matrix, where each row is a feature vector, and `Y` is a vector of labels, similar to the previous assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkMTgddvSiAX"
      },
      "source": [
        "### Question 1.2\n",
        "Implement `estimated_loss`.\n",
        "\n",
        "_Points:_ 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a6RuURhSiAX"
      },
      "outputs": [],
      "source": [
        "def estimated_loss(f, X, Y):\n",
        "    \"\"\"\n",
        "    Estimate the expected loss for a given predictor function.\n",
        "\n",
        "    Parameters:\n",
        "    f (function): Predictor function that takes an input feature matrix X and returns predicted values.\n",
        "    X (numpy.ndarray): Input feature matrix.\n",
        "    Y (numpy.ndarray): Target vector.\n",
        "\n",
        "    Returns:\n",
        "    loss (float): Estimate of the expected loss.\n",
        "    \"\"\"\n",
        "\n",
        "    ### YOUR CODE HERE ###\n",
        "\n",
        "    loss = 0 # this is a placeholder, replace it with the correct value\n",
        "\n",
        "    ######################\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCWA3wKtSiAX"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q1_2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J35lC9gGSiAX"
      },
      "source": [
        "Now we can plot $L(f_\\text{Bayes})$, $L(f^*_p)$, $\\mathbb{E}[L(\\hat f_{D, p})]$, and $\\mathbb{E}[\\hat L(\\hat f_{D, p})]$ for various values of $p$.\n",
        "\n",
        "You should see the same trends as we discussed in class.\n",
        "In particular, the irreducible error $L(f_\\text{Bayes})$ is the lowest; however, it is not zero because of the noise in the data.\n",
        "The approximation error $L(f^*_p)- L(f_\\text{Bayes})$ should decrease as $p$ increases.\n",
        "The estimation error $\\mathbb{E}[L(\\hat f_{D, p})] - L(f^*_p)$ should increase as $p$ increases, which can explained due to $\\mathbb{E}[L(\\hat f_{D, p})] - \\mathbb{E}[\\hat L(\\hat f_{D, p})]$ getting larger as $p$ increases.\n",
        "\n",
        "You can also use the slider to change the size of the dataset $n$.\n",
        "You should notice that as $n$ increases, the estimation error decreases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r1dpQZZ8SiAY"
      },
      "outputs": [],
      "source": [
        "# @title Plot\n",
        "\n",
        "# degrees = [1, 2, 3, 4, 5, 6, 7]\n",
        "degrees = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "\n",
        "# Define the function to update the plot based on the value of n and show_plot checkbox\n",
        "def update_plot_true_loss(n, show_plot):\n",
        "    if show_plot:\n",
        "        np.random.seed(random_seed)\n",
        "        # Number of different train datasets to use\n",
        "        num_datasets = 100\n",
        "\n",
        "        # Calculate the loss for each polynomial degree using closed_form_learner\n",
        "        L_f_star = []\n",
        "        L_f_hat = []\n",
        "        L_hat_f_hat = []\n",
        "\n",
        "        # Calculate the loss for f_bayes\n",
        "        L_f_bayes = estimated_loss(f_bayes, X_exp, Y_exp)\n",
        "\n",
        "        for degree in degrees:\n",
        "            L_hat_f_hat_temp = []\n",
        "            L_f_hat_temp = []\n",
        "\n",
        "            coeffs = np.polyfit(X_exp, Y_exp, degree)\n",
        "            f_star = lambda x: np.polyval(coeffs, x)\n",
        "\n",
        "            # Calculate the estimated loss\n",
        "            L = estimated_loss(f_star, X_exp, Y_exp)\n",
        "            L_f_star.append(L)\n",
        "\n",
        "            for _ in range(num_datasets):\n",
        "                # Generate new train dataset\n",
        "                X_train_raw = np.random.uniform(0, 4, n)\n",
        "                X_train = np.c_[np.ones(n), X_train_raw]\n",
        "                noise_train = np.random.normal(0, 1, n)\n",
        "                Y_train = f_bayes(X_train_raw) + noise_train\n",
        "\n",
        "                # Transform the feature matrix to polynomial features\n",
        "                X_train_poly = phi_p(X_train, degree)\n",
        "\n",
        "                # Fit the model using closed form solution\n",
        "                f_hat, w_hat = closed_form_learner(X_train_poly, Y_train)\n",
        "\n",
        "                # Calculate the estimated loss on train data\n",
        "                L_hat = estimated_loss(f_hat, X_train_poly, Y_train)\n",
        "                L_hat_f_hat_temp.append(L_hat)\n",
        "\n",
        "                # Calculate the estimated loss on the entire dataset\n",
        "                X_poly = phi_p(np.c_[np.ones(X_exp.shape[0]), X_exp], degree)\n",
        "                L = estimated_loss(f_hat, X_poly, Y_exp)\n",
        "                L_f_hat_temp.append(L)\n",
        "\n",
        "            # Take the average of the losses\n",
        "            L_hat_f_hat.append(np.mean(L_hat_f_hat_temp))\n",
        "            L_f_hat.append(np.mean(L_f_hat_temp))\n",
        "\n",
        "        # Plot the estimated loss as a function of polynomial degrees and the closed form learner loss\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(degrees, L_f_star, color='green', marker='o', label=r'$L(f^*_p)$', linewidth=3, markersize=10)\n",
        "        plt.plot(degrees, L_f_hat, color='orange', marker='x', linestyle='--', label=r'$\\mathbb{E}[L(\\hat{f}_{D, p})]$', linewidth=3, markersize=10)\n",
        "        plt.plot(degrees, L_hat_f_hat, color='purple', marker='x', linestyle='--', label=r'$\\mathbb{E}[\\hat{L}(\\hat{f}_{D, p})]$', linewidth=3, markersize=10)\n",
        "        plt.axhline(y=L_f_bayes, color='black', linestyle='-', label=r'$L(f_{Bayes})$', linewidth=3)\n",
        "        plt.xlabel('Polynomial Degree p')\n",
        "        plt.ylim(0.2, 3)\n",
        "        plt.legend(loc='lower left')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        clear_output()\n",
        "\n",
        "# Create a slider for the variable n and a checkbox for showing/hiding the plot\n",
        "n_slider_true_loss = widgets.IntSlider(value=30, min=10, max=200, step=2, description='n')\n",
        "show_plot_checkbox_true_loss = widgets.Checkbox(value=False, description='Show Plot')\n",
        "\n",
        "# Use interactive_output to update the plot based on the slider and checkbox values\n",
        "interactive_plot_true_loss = widgets.interactive_output(update_plot_true_loss, {'n': n_slider_true_loss, 'show_plot': show_plot_checkbox_true_loss})\n",
        "\n",
        "# Display the slider, checkbox, and the plot\n",
        "display(n_slider_true_loss, show_plot_checkbox_true_loss, interactive_plot_true_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-WaFAeZSiAY"
      },
      "source": [
        "Recall that we would like to select the predictor that minimizes the expected loss.\n",
        "If we had access to the above plot we would look for the value of $p$ that minimizes $\\mathbb{E}[L(\\hat f_{p})]$.\n",
        "Then, we would select $\\hat f_{p}$ as our predictor.\n",
        "However, in practice you do not have access to the expected loss, so you would need to estimate it using a test set, which is the topic of the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSgJDopmSiAY"
      },
      "source": [
        "# Part 2: Picking the Best Polynomial Predictor\n",
        "\n",
        "In practice we only have access to a single dataset $\\cal{D}$.\n",
        "So we can only talk about the predictors $\\hat f_p$ learned from this dataset.\n",
        "As such, we will work with the expected loss $L(\\hat f_p)$ of our predictor, instead of its expected value across all datasets $\\mathbb{E}[L(\\hat f_{D, p})]$.\n",
        "<!-- We would like to plot an estimate of $\\mathbb{E}[L(\\hat f_{D, p})]$ so that we can select the polynomial degree $p$ that gives the minimum expected loss. -->\n",
        "<!-- To do this we will need to split our dataset into a training and test set -->\n",
        "To get a good estimate of $L(\\hat f_p)$ we will need to split our dataset into a training and test set.\n",
        "$$\\cal{D}_\\text{train} = ((\\boldsymbol{x}_1, y_1), \\ldots, (\\boldsymbol{x}_{n-m}, y_{n-m})),$$\n",
        "$$\\cal{D}_\\text{test} = ((\\boldsymbol{x}_{n-m+1}, y_{n-m+1}), \\ldots, (\\boldsymbol{x}_n, y_n)).$$\n",
        "Our learner will only use the training set to learn the predictor $\\hat f_p$ that minimizes\n",
        "$\\hat L_\\text{train}(f_p) = \\frac{1}{n-m} \\sum_{i=1}^{n-m} \\ell(f_p(x_i), y_i)$ over all $f_p \\in \\cal{F}_p$.\n",
        "<!-- Using the training set we can calculate  -->\n",
        "<!-- $$\\hat L_\\text{train}(\\hat f_p) = \\frac{1}{n-m} \\sum_{i=1}^{n-m} \\ell(\\hat f_p(x_i), y_i)$$ -->\n",
        "<!-- which is an estimate of $\\mathbb{E}[\\hat L(\\hat f_{D, p})]$. -->\n",
        "Using the test set we can then calculate\n",
        "$$\\hat L_\\text{test}(\\hat f_p) = \\frac{1}{m} \\sum_{i=n-m+1}^{n} \\ell(\\hat f_p(x_i), y_i)$$\n",
        "which is a good estimate of $L(\\hat f_{D, p})$.\n",
        "\n",
        "You need to implement `split_dataset` which splits the dataset `X`, `Y` into a training set `X_train`, `Y_train` and test set `X_test`, `Y_test`.\n",
        "Instead of specifying the size of the test set $m$, it is more common to specify what percentage of the dataset should be used for the training set.\n",
        "The argument `train_size` represents this percentage.\n",
        "If the percentage of the training set causes the size of the training set to be a fraction, then the training set should be rounded down to the nearest integer.\n",
        "For example, if the dataset has 10 samples and `train_size` is 0.75, then the training set should have 7 samples and the test set should have 3 samples.\n",
        "If `train_size=0`, then `X_train`, `Y_train` should be empty numpy arrays, while if `train_size=1`, then `X_test`, `Y_test` should be empty numpy arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY04FYDPSiAY"
      },
      "source": [
        "### Question 2.1\n",
        "\n",
        "Implement `split_dataset`.\n",
        "\n",
        "_Points:_ 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNgNhrqsSiAY"
      },
      "outputs": [],
      "source": [
        "def split_dataset(X, Y, train_size=0.5):\n",
        "    \"\"\"\n",
        "    Splits the dataset into training and test sets.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix.\n",
        "    Y (numpy.ndarray): Target vector.\n",
        "    train_size (float): Proportion of the dataset to include in the training set.\n",
        "\n",
        "    Returns:\n",
        "    X_train (numpy.ndarray): Training feature matrix.\n",
        "    Y_train (numpy.ndarray): Training target vector.\n",
        "    X_test (numpy.ndarray): Test feature matrix.\n",
        "    Y_test (numpy.ndarray): Test target vector.\n",
        "    \"\"\"\n",
        "\n",
        "    ### YOUR CODE HERE ###\n",
        "\n",
        "    X_train = X # this is a placeholder, replace it with the correct value\n",
        "    Y_train = Y # this is a placeholder, replace it with the correct value\n",
        "\n",
        "    X_test = X # this is a placeholder, replace it with the correct value\n",
        "    Y_test = Y # this is a placeholder, replace it with the correct value\n",
        "\n",
        "    ######################\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgE7V5l9SiAY"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q2_1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-3ABxDPSiAY"
      },
      "source": [
        "First, lets assume we still have the ability to compute the expected loss $L(\\hat f_p)$, and see how our estimates $\\hat L_\\text{train}(\\hat f_p)$ and $\\hat L_\\text{test}(\\hat f_p)$ compare.\n",
        "\n",
        "The first slider for $n$ is the size of the dataset.\n",
        "While the second slider \"random seed\" is the random seed used to generate the dataset of size $n$.\n",
        "Changing the random seed should be thought of as getting an entirely new dataset of size $n$.\n",
        "We have used `train_size = 0.5` for the split.\n",
        "\n",
        "In the plot below you should see that for most datasets (i.e. random seed values) the test loss is a better estimate of the expected loss than the training loss.\n",
        "You should also see that increasing $n$ causes both the training and test loss to become better estimates of the expected loss, as expected.\n",
        "Since we only have access to one dataset we could not plot the expected values of the losses across datasets.\n",
        "In particular, we could not plot $\\mathbb{E}[L(\\hat f_{D, p})]$ and $\\mathbb{E}[\\hat L(\\hat f_{D, p})]$, but instead had to plot their estimates based on a single dataset split into a training and test set.\n",
        "This is why for most datasets the behaviour of $\\hat L_\\text{test}(\\hat f_p)$ resembles that of $\\mathbb{E}[L(\\hat f_{D, p})]$ from the previous plot.\n",
        "Similarly $\\hat L_\\text{test}(\\hat f_p)$ resembles the behaviour of $\\mathbb{E}[\\hat L(\\hat f_{D, p})]$.\n",
        "However, there are some datasets where the behaviour appears different, which is expected since we are only looking at a single dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3ix7UWGJSiAY"
      },
      "outputs": [],
      "source": [
        "# @title Plot\n",
        "\n",
        "def update_plot_sample_loss_all(seed, n, show_plot):\n",
        "    if show_plot:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        # Number of data points\n",
        "        # n = 60\n",
        "\n",
        "        # Generate X values uniformly between 0 and 4\n",
        "        X_raw = np.random.uniform(0, 4, n)\n",
        "        X = np.c_[np.ones(n), X_raw]\n",
        "\n",
        "        # Generate Y values\n",
        "        noise = np.random.normal(0, 1, n)\n",
        "        Y = f_bayes(X_raw) + noise\n",
        "\n",
        "        X_train, Y_train, X_test, Y_test = split_dataset(X, Y, train_size=0.5)\n",
        "\n",
        "        # Calculate the loss for each polynomial degree using closed_form_learner\n",
        "        L_f_bayes = estimated_loss(f_bayes, X_exp, Y_exp)\n",
        "        L_f_star = []\n",
        "        L_f_hat = []\n",
        "        L_hat_f_hat = []\n",
        "        L_hat_test_f_hat = []\n",
        "\n",
        "        for degree in degrees:\n",
        "            coeffs = np.polyfit(X_exp, Y_exp, degree)\n",
        "            f_star = lambda x: np.polyval(coeffs, x)\n",
        "\n",
        "            # Calculate the estimated loss\n",
        "            L = estimated_loss(f_star, X_exp, Y_exp)\n",
        "            L_f_star.append(L)\n",
        "\n",
        "            # Transform the feature matrix to polynomial features\n",
        "            X_train_poly = phi_p(X_train, degree)\n",
        "\n",
        "            # Fit the model using closed form solution\n",
        "            f_hat, w_hat = closed_form_learner(X_train_poly, Y_train)\n",
        "\n",
        "            # Calculate the estimated loss on the training data\n",
        "            L_hat = estimated_loss(f_hat, X_train_poly, Y_train)\n",
        "            L_hat_f_hat.append(L_hat)\n",
        "\n",
        "            X_poly = phi_p(np.c_[np.ones(X_exp.shape[0]), X_exp], degree)\n",
        "            L = estimated_loss(f_hat, X_poly, Y_exp)\n",
        "            L_f_hat.append(L)\n",
        "\n",
        "            X_test_poly = phi_p(X_test, degree)\n",
        "            L_hat_test = estimated_loss(f_hat, X_test_poly, Y_test)\n",
        "            L_hat_test_f_hat.append(L_hat_test)\n",
        "\n",
        "        # Plot the estimated loss as a function of polynomial degrees and the closed form learner loss\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(degrees, L_f_star, color='green', marker='o', label=r'$L(f^*_p)$', linewidth=3, markersize=10)\n",
        "        plt.plot(degrees, L_f_hat, color='orange', marker='x', linestyle='--', label=r'$L(\\hat{f}_p)$', linewidth=3, markersize=10)\n",
        "        plt.plot(degrees, L_hat_f_hat, color='purple', marker='x', linestyle='--', label=r'$\\hat{L}_{train}(\\hat{f}_p)$', linewidth=3, markersize=10)\n",
        "        plt.plot(degrees, L_hat_test_f_hat, color = 'blue', marker='x', linestyle='--', label=r'$\\hat{L}_{test}(\\hat{f}_p)$', linewidth=3, markersize=10)\n",
        "        plt.axhline(y=L_f_bayes, color='black', linestyle='-', label=r'$L(f_{Bayes})$', linewidth=3)\n",
        "        plt.xlabel('Polynomial Degree p')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        clear_output()\n",
        "\n",
        "# Create a slider for the variable see and a checkbox for showing/hiding the plot\n",
        "seed_slider_sample_loss_all = widgets.IntSlider(value=1, min=1, max=10, step=1, description='random seed', style={'description_width': 'initial'})\n",
        "n_slider_sample_loss_all = widgets.IntSlider(value=60, min=10, max=500, step=5, description='n')\n",
        "show_plot_checkbox_sample_loss_all = widgets.Checkbox(value=False, description='Show Plot')\n",
        "\n",
        "# Use interactive_output to update the plot based on the slider and checkbox values\n",
        "interactive_plot_sample_loss_all = widgets.interactive_output(update_plot_sample_loss_all, {'n': n_slider_sample_loss_all, 'seed': seed_slider_sample_loss_all, 'show_plot': show_plot_checkbox_sample_loss_all})\n",
        "\n",
        "# Display the slider, checkbox, and the plot\n",
        "display(n_slider_sample_loss_all, seed_slider_sample_loss_all, show_plot_checkbox_sample_loss_all, interactive_plot_sample_loss_all)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYPicvDiSiAY"
      },
      "source": [
        "Let us now simulate the process of selecting the best predictor.\n",
        "In practice we only have access to $\\hat L_{\\text{train}}(\\hat f_p)$ and $\\hat L_{\\text{test}}(\\hat f_p)$ for a single dataset of size $n$.\n",
        "In this case we set `n=100` and split the traning and test set evenly `train_size=0.5`.\n",
        "\n",
        "First, for each value of $p \\in \\{1, \\dots, 10\\}$ we use `closed_form_learner` only on the training set with the function class $\\cal{F}_p$ to get 10 different predictors $\\hat f_1, \\dots, \\hat f_{10}$.\n",
        "Now, we need to select the best predictor predictor from $\\hat f_1, \\dots, \\hat f_{10}$.\n",
        "To do this we plot $\\hat L_{\\text{train}}(\\hat f_p)$ and $\\hat L_{\\text{test}}(\\hat f_p)$.\n",
        "You should see the training loss $\\hat L_{\\text{train}}(\\hat f_p)$ decreases as $p$ increases, indicating that our `closed_form_learner` is better able to fit the training data as $p$ increases.\n",
        "However, we want to choose the predictor that minimizes the expected loss, which we saw is better estimated by the test loss $\\hat L_{\\text{test}}(\\hat f_p)$.\n",
        "Thus, based on the plot below, we would select $\\hat f_4$ as our predictor, since it has the lowest test loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1EeaHFTKSiAY"
      },
      "outputs": [],
      "source": [
        "# @title Plot\n",
        "\n",
        "# Initialize variables to store the predictors\n",
        "predictor_degree_2 = None\n",
        "predictor_degree_4 = None\n",
        "predictor_degree_10 = None\n",
        "\n",
        "def update_plot_sample_loss_fixed(show_plot):\n",
        "    global predictor_degree_2, predictor_degree_4, predictor_degree_10\n",
        "\n",
        "    if show_plot:\n",
        "        seed = 2\n",
        "        n = 100\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        # Generate X values uniformly between 0 and 4\n",
        "        X_raw = np.random.uniform(0, 4, n)\n",
        "        X = np.c_[np.ones(n), X_raw]\n",
        "\n",
        "        # Generate Y values\n",
        "        noise = np.random.normal(0, 1, n)\n",
        "        Y = f_bayes(X_raw) + noise\n",
        "\n",
        "        X_train, Y_train, X_test, Y_test = split_dataset(X, Y, train_size=0.5)\n",
        "\n",
        "        # Calculate the loss for each polynomial degree using closed_form_learner\n",
        "        L_hat_f_hat = []\n",
        "        L_hat_test_f_hat = []\n",
        "\n",
        "        for degree in degrees:\n",
        "            # Transform the feature matrix to polynomial features\n",
        "            X_train_poly = phi_p(X_train, degree)\n",
        "\n",
        "            # Fit the model using closed form solution\n",
        "            f_hat, w_hat = closed_form_learner(X_train_poly, Y_train)\n",
        "\n",
        "            # Save the predictors for degrees 2, 4, and 10\n",
        "            if degree == 2:\n",
        "                predictor_degree_2 = f_hat\n",
        "            elif degree == 4:\n",
        "                predictor_degree_4 = f_hat\n",
        "            elif degree == 10:\n",
        "                predictor_degree_10 = f_hat\n",
        "\n",
        "            # Calculate the estimated loss on the training data\n",
        "            L_hat = estimated_loss(f_hat, X_train_poly, Y_train)\n",
        "            L_hat_f_hat.append(L_hat)\n",
        "\n",
        "            X_test_poly = phi_p(X_test, degree)\n",
        "            L_hat_test = estimated_loss(f_hat, X_test_poly, Y_test)\n",
        "            L_hat_test_f_hat.append(L_hat_test)\n",
        "\n",
        "        # Plot the estimated loss as a function of polynomial degrees and the closed form learner loss\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(degrees, L_hat_f_hat, color='purple', marker='x', linestyle='--', label=r'$\\hat{L}_{train}(\\hat{f}_p)$', linewidth=3, markersize=10)\n",
        "        plt.plot(degrees, L_hat_test_f_hat, color = 'blue', marker='x', linestyle='--', label=r'$\\hat{L}_{test}(\\hat{f}_p)$', linewidth=3, markersize=10)\n",
        "        plt.xlabel('Polynomial Degree p')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        clear_output()\n",
        "\n",
        "# Create a checkbox for showing/hiding the plot\n",
        "show_plot_checkbox_sample_loss_fixed = widgets.Checkbox(value=False, description='Show Plot')\n",
        "\n",
        "# Use interactive_output to update the plot based on the checkbox value\n",
        "interactive_plot_sample_loss_fixed = widgets.interactive_output(update_plot_sample_loss_fixed, {'show_plot': show_plot_checkbox_sample_loss_fixed})\n",
        "\n",
        "# Display the checkbox and the plot\n",
        "display(show_plot_checkbox_sample_loss_fixed, interactive_plot_sample_loss_fixed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXIzylsBSiAY"
      },
      "source": [
        "We can visualize the predictor $\\hat f_4$ by plotting it on the same plot as $f_\\text{Bayes}$.\n",
        "We can also compare it to predictors that have higher test loss, such as $\\hat f_2$ and $\\hat f_{10}$.\n",
        "\n",
        "You should see that $\\hat f_4$ is a better approximation of $f_\\text{Bayes}$ than $\\hat f_2$ and $\\hat f_{10}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kgFWrJ_uSiAY"
      },
      "outputs": [],
      "source": [
        "# @title Plot\n",
        "\n",
        "# Define the function to update the plot based on the selected degree, n, and random seed\n",
        "def update_plot_best_f(show_plot):\n",
        "    if show_plot:\n",
        "        deg_2_values = predictor_degree_2(phi_p(np.c_[np.ones(x.shape[0]), x], 2))\n",
        "        deg_4_values = predictor_degree_4(phi_p(np.c_[np.ones(x.shape[0]), x], 4))\n",
        "        deg_10_values = predictor_degree_10(phi_p(np.c_[np.ones(x.shape[0]), x], 10))\n",
        "\n",
        "        # Plot the generated data points and the polynomial fit\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(x, f_bayes(x), color='black', label=r'$f_{Bayes}$', linewidth=3)\n",
        "        plt.plot(x, deg_2_values, color='orange', linestyle='--', label=fr'$\\hat f_2$', linewidth=3)\n",
        "        plt.plot(x, deg_4_values, color='green', linestyle='-', label=fr'$\\hat f_4$', linewidth=3)\n",
        "        plt.plot(x, deg_10_values, color='blue', linestyle=':', label=r'$\\hat{f}_{10}$', linewidth=3)\n",
        "        plt.xlabel('X')\n",
        "        plt.ylabel('Y')\n",
        "        plt.ylim(0.2, 7.2)\n",
        "        plt.xlim(-0.2, 4.2)\n",
        "        plt.legend(loc='upper left')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        clear_output()\n",
        "\n",
        "# Create a checkbox for showing/hiding the plot\n",
        "show_plot_checkbox_best_f = widgets.Checkbox(value=False, description='Show Plot')\n",
        "\n",
        "# Use interactive_output to update the plot based on the checkbox value\n",
        "interactive_plot_best_f = widgets.interactive_output(update_plot_best_f, {'show_plot': show_plot_checkbox_best_f})\n",
        "\n",
        "# Display the checkbox and the plot\n",
        "display(show_plot_checkbox_best_f, interactive_plot_best_f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-9GdOr9SiAZ"
      },
      "source": [
        "# Part 3: Regularization\n",
        "\n",
        "In this section we will study the effect of regularization on our predictors.\n",
        "To do this you will need to implement a regularized version of the batch gradient descent learner `regularized_bgd_learner`.\n",
        "This learner should take its gradient steps with respect to the gradient of the regularized estimated loss\n",
        "$$\\hat L_\\lambda(\\boldsymbol{w}) = \\frac{1}{n} \\sum_{i=1}^n \\ell(\\boldsymbol{x_i}^\\top \\boldsymbol{w}, y_i) + \\frac{\\lambda}{n} \\sum_{j=1}^{d} w_j^2.$$\n",
        "For your implementation assume that the degree of the polynomial $p$ is 1.\n",
        "This means you do not need to apply `phi_p` to the features `X` in `regularized_bgd_learner`.\n",
        "The reason for this is that it makes the implementation simpler and it is without loss of generality since when we use your implementation to plot things we can simply apply `phi_p` first, before passing the features to `regularized_bgd_learner`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sionV5j4SiAZ"
      },
      "source": [
        "### Question 3.1\n",
        "\n",
        "Implement `regularized_bgd_learner`.\n",
        "\n",
        "_Points:_ 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byPWFoZxSiAZ"
      },
      "outputs": [],
      "source": [
        "def regularized_bgd_learner(X, Y, step_size=0.01, lambda_=0.1, epochs=1000, random_seed=42):\n",
        "    \"\"\"\n",
        "    Performs batch gradient descent with L2 regularization to learn the weights.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix of size (n, d+1), where n is the number of samples\n",
        "                       and d is the number of features. The first column should be all 1s.\n",
        "    Y (numpy.ndarray): Target vector of size (n, 1).\n",
        "    alpha (float): Learning rate.\n",
        "    lambda_ (float): Regularization parameter.\n",
        "    epochs (int): Number of iterations for gradient descent.\n",
        "\n",
        "    Returns:\n",
        "    predictor (function): A function that takes a feature vector and returns a predicted value.\n",
        "    w (numpy.ndarray): The learned weights.\n",
        "    \"\"\"\n",
        "    n, d = X[:, 1:].shape\n",
        "    np.random.seed(random_seed)\n",
        "    w = np.random.randn(d+1) # initialize the weights randomly\n",
        "\n",
        "    ### YOUR CODE HERE ###\n",
        "\n",
        "\n",
        "    ######################\n",
        "\n",
        "    def predictor(x):\n",
        "        return x @ w\n",
        "\n",
        "    return predictor, w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjfP4QvcSiAZ"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q3_1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWnfNMqVSiAZ"
      },
      "source": [
        "We plot the effect of regularization on the predictor `regularized_bgd_learner` outputs, for various values of $\\lambda$.\n",
        "We will use the function class $\\cal{F}_9$, which contains polynomials of degree 9 or less.\n",
        "When $\\lambda = 0$ we should get almost the same predictor as the `closed_form_learner` (the only error is due to gradient descent potentially not being run for enough epochs).\n",
        "Since the function class $\\cal{F}_9$ is very large we should expect the predictor to overfit the data when $\\lambda = 0$.\n",
        "As $\\lambda$ increases you should see that the predictor becomes less complicated and thus less likely to overfit the data.\n",
        "When $\\lambda$ gets too large you should see that the predictor becomes too simple and thus underfits the data.\n",
        "\n",
        "We also plot the expected predictor $\\bar f_9$ based on 10 datasets.\n",
        "Note that we only used 10 datasets due to computational reasons.\n",
        "Ideally we would use more datasets to get a better estimate of $\\bar f_9$.\n",
        "What you should see in the plot is that when $\\lambda = 0$ the expected predictor $\\bar f_9$ is approximately equal to $f_\\text{Bayes}$ (it would be exactly equal if we used more datasets), which means the Bias is low.\n",
        "As $\\lambda$ increases $\\bar f_9$ becomes less complicated and is no longer similar to $f_\\text{Bayes}$, which means the Bias increases.\n",
        "When $\\lambda$ gets too large $\\bar f_9$ becomes too simple and has high Bias.\n",
        "\n",
        "You should also notice that for small $\\lambda$ the predictor $\\hat f_9$, varies a lot across datasets (random seed values) relative to $\\bar f_9$, which means the Variance is high.\n",
        "While for large $\\lambda$ the predictor $\\hat f_9$ varies less across datasets relative to $\\bar f_9$, which means the Variance is low."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pMouz129SiAZ"
      },
      "outputs": [],
      "source": [
        "# @title Plot\n",
        "\n",
        "# Define the function to update the plot based on the selected random seed, lambda, and show_plot\n",
        "def update_plot_f_bar_reg(random_seed, lambda_, show_plot):\n",
        "    degree = 9\n",
        "    n = 40\n",
        "    if show_plot:\n",
        "        # Fit the polynomial to the data\n",
        "        w_star = np.polyfit(X_exp, Y_exp, degree)\n",
        "\n",
        "        # Generate y values for the fitted polynomial\n",
        "        f_star = np.polyval(w_star, x)\n",
        "\n",
        "        # Generate new train dataset\n",
        "        np.random.seed(random_seed)\n",
        "        X_train_raw = np.random.uniform(0, 4, n)\n",
        "        X_train = np.c_[np.ones(n), X_train_raw]\n",
        "        noise_train = np.random.normal(0, 1, n)\n",
        "        Y_train = f_bayes(X_train_raw) + noise_train\n",
        "\n",
        "        # Transform the feature matrix to polynomial features\n",
        "        X_train_poly = phi_p(X_train, degree)\n",
        "\n",
        "        # Fit the model using regularized batch gradient descent\n",
        "        f_hat, w_hat = regularized_bgd_learner(X_train_poly, Y_train, step_size=0.075, lambda_=lambda_, epochs=10000)\n",
        "\n",
        "        # Generate y values for the fitted polynomial from regularized_bgd_learner\n",
        "        f_hat_values = f_hat(phi_p(np.c_[np.ones(x.shape[0]), x], degree))\n",
        "\n",
        "        # Calculate the average predictor\n",
        "        num_datasets = 10\n",
        "        f_bar_values = np.zeros_like(x)\n",
        "\n",
        "        for _ in range(num_datasets):\n",
        "            X_train_raw = np.random.uniform(0, 4, n)\n",
        "            X_train = np.c_[np.ones(n), X_train_raw]\n",
        "            noise_train = np.random.normal(0, 1, n)\n",
        "            Y_train = f_bayes(X_train_raw) + noise_train\n",
        "\n",
        "            X_train_poly = phi_p(X_train, degree)\n",
        "            f_bar, w_bar = regularized_bgd_learner(X_train_poly, Y_train, step_size=0.075, lambda_=lambda_, epochs=10000)\n",
        "            f_bar_values += f_bar(phi_p(np.c_[np.ones(x.shape[0]), x], degree))\n",
        "\n",
        "        f_bar_values /= num_datasets\n",
        "\n",
        "        # Plot the generated data points and the polynomial fit\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(x, f_bayes(x), color='black', label=r'$f_{Bayes}$', linewidth=3)\n",
        "        plt.plot(x, f_star, color='green', linestyle='-', label=fr'$f^*_{degree}$', linewidth=3)\n",
        "        plt.plot(x, f_hat_values, color='orange', linestyle='--', label=fr'$\\hat f_{degree}$ with n={n}', linewidth=3)\n",
        "        plt.plot(x, f_bar_values, color='blue', linestyle='-', label=fr'$\\bar f_{degree}$ over {num_datasets} datasets', linewidth=3)\n",
        "        plt.scatter(X_train_raw, Y_train, color='orange', alpha=0.5, label='Datapoints')\n",
        "        plt.xlabel('X')\n",
        "        plt.ylabel('Y')\n",
        "        plt.ylim(0.2, 7.2)\n",
        "        plt.xlim(-0.2, 4.2)\n",
        "        plt.legend(loc='upper left')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        clear_output()\n",
        "\n",
        "# Create sliders for the random seed and lambda\n",
        "random_seed_slider_f_bar_reg = widgets.IntSlider(value=1, min=1, max=10, step=1, description='Random Seed', style={'description_width': 'initial'})\n",
        "lambda_slider_f_bar_reg = widgets.FloatLogSlider(\n",
        "    value=0.01,\n",
        "    base=10,\n",
        "    min=-4,  # 10^-4 = 0.0001\n",
        "    max=2,   # 10^1 = 10.0\n",
        "    step=0.1,\n",
        "    description='Lambda',\n",
        ")\n",
        "show_plot_checkbox_f_bar_reg = widgets.Checkbox(value=False, description='Show Plot')\n",
        "\n",
        "# Use interactive_output to update the plot based on the slider values\n",
        "interactive_plot_f_bar_reg = widgets.interactive_output(update_plot_f_bar_reg,\n",
        "                                                    {'random_seed': random_seed_slider_f_bar_reg,\n",
        "                                                     'lambda_': lambda_slider_f_bar_reg,\n",
        "                                                     'show_plot': show_plot_checkbox_f_bar_reg})\n",
        "\n",
        "# Display the sliders and the plot\n",
        "display(random_seed_slider_f_bar_reg, lambda_slider_f_bar_reg, show_plot_checkbox_f_bar_reg, interactive_plot_f_bar_reg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHWEvjckSiAZ"
      },
      "source": [
        "To conclude, we can plot training and test loss for various values of $\\lambda$.\n",
        "You should see that the training loss decreases as $\\lambda$ increases, since it allows the predictor to become more complicated.\n",
        "However, the test loss should at first decrease as $\\lambda$ increases (bias is reducing a lot), but around $\\lambda = 1$ it should start to increase (variance is increasing a lot).\n",
        "\n",
        "Similar to [Part 2](#part-2-picking-the-best-polynomial-predictor), we would use the test loss to select the best predictor, which in this case would be the predictor output by `regularized_bgd_learner` with $\\lambda$ slightly less than 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-fJysMSVSiAZ"
      },
      "outputs": [],
      "source": [
        "# @title Plot\n",
        "\n",
        "# Function to update the plot based on the checkbox value\n",
        "def update_plot_reg(show_plot):\n",
        "    if show_plot:\n",
        "        # Number of data points\n",
        "        n = 18\n",
        "\n",
        "        # Set the random seed for reproducibility\n",
        "        random_seed = 7\n",
        "        np.random.seed(random_seed)\n",
        "\n",
        "        X_raw = np.random.uniform(0, 4, n)\n",
        "        X = np.c_[np.ones(n), X_raw]\n",
        "\n",
        "        # Generate noise from a Gaussian distribution with mean 0 and variance 1\n",
        "        noise_train = np.random.normal(0, 1, n)\n",
        "\n",
        "        # Calculate Y values using f_bayes\n",
        "        Y = f_bayes(X_raw) + noise_train\n",
        "\n",
        "        X_train, Y_train, X_test, Y_test = split_dataset(X, Y, train_size=0.5)\n",
        "\n",
        "        # Define the range of lambda values to test\n",
        "        lambda_values = np.logspace(2, -2, 10)\n",
        "\n",
        "        # Initialize lists to store the losses\n",
        "        L_hat_f_hat_lambda = []\n",
        "        L_hat_test_f_hat_lambda = []\n",
        "\n",
        "        # Degree of polynomial features\n",
        "        degree = 9\n",
        "\n",
        "        # Train and evaluate the model for each lambda value\n",
        "        for lambda_ in lambda_values:\n",
        "            # Transform the feature matrix to polynomial features\n",
        "            X_train_poly = phi_p(X_train, degree)\n",
        "            X_test_poly = phi_p(X_test, degree)\n",
        "\n",
        "            # Fit the model using regularized batch gradient descent\n",
        "            f_hat_lambda, w_hat_lambda = regularized_bgd_learner(X_train_poly, Y_train, step_size=0.01, lambda_=lambda_, epochs=10000)\n",
        "\n",
        "            # Calculate the estimated loss on the training data\n",
        "            L_hat = estimated_loss(f_hat_lambda, X_train_poly, Y_train)\n",
        "            L_hat_f_hat_lambda.append(L_hat)\n",
        "\n",
        "            # Calculate the estimated loss on the test data\n",
        "            L_hat_test = estimated_loss(f_hat_lambda, X_test_poly, Y_test)\n",
        "            L_hat_test_f_hat_lambda.append(L_hat_test)\n",
        "\n",
        "        # Plot the estimated loss as a function of lambda values\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(lambda_values, L_hat_f_hat_lambda, color='purple', marker='x', linestyle='--', label=r'$\\hat{L}_{train, \\lambda}(\\hat{f})$', linewidth=3, markersize=10)\n",
        "        plt.plot(lambda_values, L_hat_test_f_hat_lambda, color = 'blue', marker='x', linestyle='--', label=r'$\\hat{L}_{test, \\lambda}(\\hat{f})$', linewidth=3, markersize=10)\n",
        "        plt.xscale('log')\n",
        "        plt.gca().invert_xaxis()  # Invert the x-axis\n",
        "        plt.xlabel(r'$\\lambda$')\n",
        "        plt.ylim(0.2, 2.7)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        clear_output()\n",
        "\n",
        "# Create a checkbox for showing/hiding the plot\n",
        "show_plot_checkbox_reg = widgets.Checkbox(value=False, description='Show Plot')\n",
        "\n",
        "# Use interactive_output to update the plot based on the checkbox value\n",
        "interactive_plot_reg = widgets.interactive_output(update_plot_reg, {'show_plot': show_plot_checkbox_reg})\n",
        "\n",
        "# Display the checkbox and the plot\n",
        "display(show_plot_checkbox_reg, interactive_plot_reg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hft_9dASiAZ"
      },
      "source": [
        "---\n",
        "\n",
        "To double-check your work, the cell below will rerun all of the autograder tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vZP8wTUSiAZ"
      },
      "outputs": [],
      "source": [
        "grader.check_all()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "otter_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}